# 教授との面談メモ

## 概要

- 日時：2025年5月28日 13:10-
- 内容：val_loss記録と重み付き複合モデル構築（v2/v3）に関する進捗報告、およびパラメータレンジ学習に関する新たな提案

---

## 主なトピック

### 1. 単体モデル (`image2param_single.ipynb`) の構築と val_loss の記録

- 各パラメータに対して個別に学習を行い、`val_loss` を `val_losses.json` に記録する構成を実装。
- 学習回数は `REPEAT` により制御可能（例：1回 or 10回など）。
- 実行結果は以下のようにパラメータごとに配列で保存：
  ```json
  {
    "dipCount": [0.203, 0.187],
    "hue_cos": [0.110, 0.097],
    ...
  }
  ```
- JSON形式を採用した理由は：
  - 各パラメータをキーで管理しやすい
  - 配列で履歴を保持できる
  - 平均など統計処理がしやすい

### 2. 複合モデル v2 / v3 の実装と違い

#### `image2params_v2.ipynb`

- 単体モデルの val_loss を使用して、出力4次元（dipCount, hue_cos, hue_sin, circleCount）を同時回帰する CNN を構築。
- `val_losses.json` の **最新値** のみを参照し、逆数＋最大値正規化で `loss_weights` を作成。
- `WeightedMSELoss` によりスケール差を吸収したマルチタスク学習を実現。

#### `image2params_v3.ipynb`

- v2を拡張し、`VAL_LOSS_MODE` によって重み決定方法を切り替え可能に。
  - `"latest"`：val_lossの最新値を使用
  - `"average"`：val_lossの履歴平均を使用
- モードに応じて `loss_weights` を切り替え、より柔軟な学習構成に。
- 正規化済みの `dipCount`, `circleCount` はZ-score逆変換、`hue` は `(cos, sin) → arctan2` により角度復元。
- 可視化では、予測結果と真値を画像上に数値で表示し、予測精度の確認が容易。

### 3. パラメータレンジに基づく画像群の学習提案（Thema v2）

- 現在の学習構成は「画像とパラメータの1対1関係」を前提としているが、創作の実感としては「ある程度のレンジが生み出す作品群」が魅力を持つことが多い。
- そこで、**レンジ → 複数画像 → 評価** という単位で学習させる流れを検討。

#### 提案フロー（初期イメージ）

- パラメータのレンジ（例：dipCount ∈ [3, 5]）を指定
- その範囲から複数の画像をランダムに生成
- ユーザがその画像群をまとめて評価（例：良い / 微妙）
- そのデータを用いて「良い画像群を生むレンジの特徴」を学習

#### 意義と可能性

- 単体画像に対する予測よりも、より抽象的・構造的な好みに迫ることが可能
- 「画像群のまとまり感」に注目した研究として、ジェネラティブアートの実感とより近い学習フレームを模索できる

---

## 備考

- 議論内容（ディスカッションログ）は面談後に記録予定
- 次回に向けたネクストアクションも当日の議論に応じて記述