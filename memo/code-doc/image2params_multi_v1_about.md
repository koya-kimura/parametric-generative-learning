# CNNによるジェネレーティブ画像からの複数パラメータ予測

このプロジェクトでは、p5.jsで生成された画像をもとに  
**形状のくびれ数（`dipCount`）**と**色相（`hue`）**を同時に回帰予測するCNNモデルを構築しています。

円環的な `hue` はベクトル表現（`cos`, `sin`）に変換して扱うことで、誤差関数を滑らかに定義できるようにしています。

---

## 🧠 タスク概要

- **入力**：RGB画像（元サイズ600×600、学習時は128×128にリサイズ）
- **出力**：以下の3つの連続値を同時に回帰
  - `dipCount`（float）
  - `hue_cos`（float）
  - `hue_sin`（float）
- **目的**：出力と真値の MSE（二乗平均誤差）を最小化する

---

## 🗂️ ディレクトリ構成

```
.
├── data/
│   └── circle-stroke/
│       ├── images/              # 生成画像（例：image_20250521_0001.png）
│       └── metadata.csv         # 各画像のパラメータ情報
├── code/
│   └── python/
│       └── image2params_multi.ipynb  # 本ノートブック
```

---

## 🔁 学習パイプライン

1. `metadata.csv` を読み込み、存在する画像とのマッチングを行う
2. ラベルに `dipCount`, `hue` を抽出し、`hue` を `(cos, sin)` に変換
3. PyTorch Dataset を定義（画像 → [dipCount, hue_cos, hue_sin]）
4. train/val に 80:20 で分割
5. DataLoader によるバッチ化
6. 出力3次元の CNN モデルを定義（最後の `fc2` が出力3次元）
7. 損失関数：`MSELoss`（3出力同時に）
8. 最適化手法：`Adam`
9. 可視化：
   - ロスカーブ（train/val）
   - 画像上に dipCount/hue の予測と正解をタイトルで表示（8枚並列）
   - hue の角度は `(cos, sin) → arctan2 → deg` で復元

---

## ✅ 予測例（出力形式）

| サンプル | dipCount（GT/pred） | hue（GT/pred, °換算） |
|----------|---------------------|------------------------|
| 1        | 3.0 / 2.9           | 120° / 118°            |
| 2        | 5.0 / 4.6           | 230° / 225°            |

---

## 🔧 今後の展望

- 他のパラメータ（`circleCount`, `startAngle`, `asp` など）を含めた拡張
- hue 予測の精度評価（角度誤差）を導入
- `torch.save` / `torch.load` によるモデル保存・推論用の整備
- 推論結果の分布を統計的に可視化（ヒストグラム・散布図など）