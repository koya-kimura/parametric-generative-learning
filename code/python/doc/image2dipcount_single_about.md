# CNNによるジェネラティブ画像からの dipCount 推定

このプロジェクトでは、p5.jsで生成された円状ストローク画像から、  
図形の「くびれの数（`dipCount`）」を予測する回帰モデルを構築します。

学習には、各画像に対応する生成パラメータを含む `metadata.csv` を用いた教師あり学習を行います。

---

## 🧠 タスク概要

- **入力**：RGB画像（元サイズ600×600、学習時は128×128にリサイズ）
- **出力**：`dipCount` を表すスカラー値（float）
- **目的**：MSE（二乗平均誤差）を最小化するように学習

---

## 🗂️ ディレクトリ構成

```
.
├── data/
│   └── circle-stroke/
│       ├── images/              # 生成された画像（例：image_20250521_0001.png）
│       └── metadata.csv         # 各画像のパラメータ情報を含むCSV
├── code/
│   └── python/
│       └── image2dipcount_single.ipynb  # 本ノートブック
```

---

## 🔁 学習パイプライン

1. `metadata.csv` を読み込み、画像ファイルとマッチング
2. `dipCount` のみをラベルとして抽出
3. PyTorch Dataset クラスを定義（画像 → dipCount のペア）
4. データを 80:20 に分割して `train` / `val` を作成
5. DataLoader でバッチ化
6. CNNモデル構築（Conv → Pool → FC → 出力1次元）
7. 損失関数：`MSELoss`
8. 最適化手法：`Adam`
9. 可視化：
   - ロスカーブ（train/val）
   - 画像と予測値の目視比較（8枚並列）

---

## ✅ 予測例（出力例）

| サンプル | 正解（GT） | 予測値 |
|----------|------------|--------|
| 1        | 3.0        | 2.87   |
| 2        | 5.0        | 4.52   |
| 3        | 4.0        | 4.11   |

---

## 🔧 今後の展望

- `hue`, `circleCount` などの他パラメータとの**同時予測**への拡張（→ `image2params_multi.ipynb` へ）
- モデル解釈（Grad-CAMなど）の導入
- ResNetやViTなど高度なCNN構造への移行